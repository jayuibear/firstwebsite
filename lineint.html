<head>
<title> Line Integrals </title>
</head>
<body>
<h1> Line integrals </h1>
<h2> Introduction </h2>
<p> In calculus of a single variable, change seemed quite easy to measure. When we investigated the notion of the directional derivative, however, we realized that once you include more dimensions, the possibilities become endless. We could see how much a function would change for a small step in any direction, not just along the x or y axes. Even around one point, the behavior of a function could change significantly depending on the direction we were headed.</p>
<p> What about integrals, then? What about integrals in a certain direction? This might seem preposterous at first. After all, integrals in space occur over entire regions, so it's not like we can just pick a direction to go with. But recall one of the geometric interpretations of double integrals--the idea of cross sections being integrated across an axis. For the sake of that chapter, we looked at cross sections for traces with respect to one axis and then integrated again to form a double integral. However, we limited these cross sections to be perpendicular to the axes. Who says we can't have a cross section that follows a diagonal path underneath the curve? Remember, a cross section's area is just an integral in two dimensions, which is just a single integral. You might wonder if perhaps we can construct this sort of integral. We'd be going on some heterodox path for sure, but it's area under a curve, a concept from Calculus I.</p>
<p> So how would we go about doing this? Imagine we have some sort of surface f(x,y), and we want to find the "directional integral" going diagonally across the floor like so: [IMAGE HERE]. What I mean is, imagine findnig the area underneath the surface along that line. By restricting the surface to just that line, however, we're basically doing a very simple integration. We still need to know how we'd calculate it, though. </p>
<p> The first question we should ask to try to tackle this problem is, "With respect to what are we integrating?" It's not with respect to x or y. We might be tempted to say both, but that would create a double integral. It seems as if we're integrating with respect to the line on the floor, but how do we express that? We can't express our bounds in both x and y at the same time, then we'd have two variables! We need a way to use a single integral to repersent tiny changes in both x and y.</p>
<p> So, let's recap what we've figured out so far. We need to integrate along the line on the floor. The line has both changing x and y values. If only we had a way to make x and y both dependent on some other variable. At this point, a light bulb should go off in your head. Make x and y dependent on some other variable? Let's parametrically define our line. The line in question here is simply y=x, which we could represent as x(t) = t, and y(t) = t. We see that a change "on the line" is really the change of the hypotenuse of a right triangle formed by changes in both x and y. Before we dig deeper into this aspect, let's remind ourselves what an integral is. It's the limit of a bunch of Riemann sums, more specifically, the areas of rectangles, only this time, our rectangle width is a little bit of the length of the line. Our height, of course, is the value of the function at a point on this small bit of length. So the area of each rectangle is "value of function" times "small bit of arc length". We of course will sum these and take the limit as the width of these rectangles approaches 0.</p>
<p> We want to integrate everything with respect to one variable, t. I always imagine t as being time--imagine traveling along this curve over a period of time and gradually adding these rectangles.</p>
<p> Let's do the easy part first, which is defining our function parametrically. The example I gave is z = x^2 + y^2. Since x and y both equal t, we can say that z= 2t^2. Think about what that means. For any bit of time (let's say, I don't know, seconds?) the height of our curve is equal to twice to our amount of time in seconds squared. Now, we need to represent our small change in arc length, which we conventionally call dS. Well, we're going to say that this tiny change in arc length is equal to a tiny change in time multiplied by something. What is this something? Well, it's going to be the length of our hypotenuse. This is of course, [insert link]. We eventually end up with [insert link]. Think about it. That makes sense, right? On a straight line, for a small change in time, the change in the hypotenuse is also going to be linear, just with a different slope.</p>
<p> So, where do we end up? Now that we have everything in terms of t, let's put it together. We end up with this integral: [put image here]. So, what if we want to integrate from (0,0) to (1,1)? You might be tempted to say it's the integral from 0 to 1. Well, in this case you'd be right, but remember, we have to consider what values of t correspond to the bounds of integration. Our final definite integral is thus [insert image].</p>
<p> Wow. Think about what we did for a second. We basically found a way to evaluaet a directional integral. And for our line, it's not really too different from a directional derivative in the reverse direction. I mean, we're just integrating our original function multiplied by some constant which accounts for our Pythagorean shenanigans. There's a more formal name for this "directional integral"--a line integral. The notation looks like this: [insert image]</p>
<p> Play around with this for different functions. If you spent a long enough time doing that, a thought might cross your mind. You could connect a bunch of these lines and calculate these line integrals, each next one starting where the last one left off. You can make these really interesting lined paths for yourself. Now, ask yourself, what would happen if we took a bunch of tiny lines and connected them together? That's right. Then we'd be looking at a curve. We can make these line integrals go over curves now! </p>
<p> No, you don't have to integrate a line integral again to account for the many different tiny lines that form up a curve. That's actually already covered in our original definition of the line integral, specifically, defining the arc length parametrically. Remember, if we zoom into certain parts of our curve, our "right triangle" will look different, meaning that our derivatives will carry different values as well. These derivatives are derived from our original function which we've defined parametrically, and our derivatives are already defined parametrically inside of our arc length formula. That means that as long as we can define our little path parametrically, we can find these the areas marked by these "cross sections." Now I think that's pretty cool, don't you? These are still called line integrals, by the way, even though they're over curves. </p>
  <h2> Vector Fields and Scalar Fields </h2>
  <p> We now have this notion of being able to accumulate a function along a certain path. This is super useful, particularly in physics. For example, we've seen that we can calculate the work done along a straight path by a force using dot products, but with a line integral, you can find the work done on a curvy path. So many things involve going from Point A to Point B, but few of them are just purely straight lines. So, let's say we want to find the work done by gravity in space onto a planet traveling on a certain path (a very useful application in astronomy). Okay, let's look at our function that we're integrating! [Insert picture of a vector field] Hmm, this is interesting. I mean, it makes sense, right? We represent force through vectors, so we're basically taking our line integral through all of these force vectors though. There's a bit of a problem, though. This collection of vectors isn't exactly like a function that we're used to, right? Normally, we'd say that when we input some values, we get another piece of our coordinate as our output. Now, though, we're inputting points and getting a vector as an output. And the important part is that we can't just represent these vectors with one number. We have to take directions into account. It's not as simple as z = f(x,y) anymore. Now, every value of x, y, and z is associated with components of vectors going in certain directions with different strengths depending on where we are in space. We're going to need a new type of function. </p>
  <p> This sort of function will require a point as an input and a vector as an output. In other words, for some point (x,y,z), our function f(x,y,z) will give us a vector. The x component of our vector will be some function of x, y, and z. Look at the diagram of the gravitational field, particularly the x components of these vectors. Notice that their relative directions and strengths depnd on where they are in space. When the actual value of x is positive, the x component of our vector is negative because it's pointing towards the origin (where our celestial body is). When x is negative, the component is positive. Notice that the x component depends on our values of y and z as well. We can apply this same logic to the y and z components. The point is, we have functions that describe the behavior of these vectors at each and every point. Again, it makes sense conceptually from the picture. </p>
  <p> As much sense as this makes, there was something that always threw me off. In our gravity diagram, we see that the x-component of each vector depends on our value of x. It's easy to get yourself confused and say, "What? x depends on x? That doesn't make any sense? How can a variable depend on itself?" But really these are two different things that have to do with the notion of x. One is our input, the value of x in space. The other is our output, the srtength of our vector in the direction parallel to the x-axis.</p>
  <p> So what on earth do we call this kind of function, and how do we notate it? Well,we call this collection of vectors a vector field. "Regular" functions are called scalar fields because sets of input values are associated with numbers. Normally, we don't call numbers "scalars," but we have to make the distniction now. Scalars are purely numbers--magnitudes. Vectors have direction, which we have to accoutn for now. </p>
  <p> Well, vector fields are new now, right? No, actually, can you think of something we've done in the past that inputs points and outputs numbers? Well, there's the gradient! The gradient is a type of vector field, is it not? We input some point, and we get a vector whose components are dependent on that point. Until now, though, we've associated gradient vector fields with some other parent function (technically called a potential function). This is actually a special susbet of vector fields caleld cosnervative vector fields, which are gradients of some scalar field. There are, however, vector fields that are not gradients of some other field. This also came as a surprise to me at first. In single-variable calculus, we learned that every functino has an antiderivative, even if it cannot be expressed with elementary mathematical functions. We can sort of think of gradients as "vector derivatives," so it can be surprising to know that some of these fields don't have a parent function. This disparity arises from the fact that there is some relationship between the different components of a vector field. For example, imagine if the x component of our vector field was x^2 + y^2, and that our y component was e^x *sin(y)*ln(z). It's impossible to think of a function whose partial derivatives with respect to x and y respectively match up with that. We'll talk more about special properties of conservative vector fields later </p>.
  <p> So, going back to the idea of calculating a line intergral across this vector field, what would we even do? Well, we know that on a straight line, work is simply force dot distance [image]. Now, though, we have two issues. We have paths that aren't straight, and we have forces that aren't constant. The first issue should be more familiar by now since we've already done line integrals over scalar fields. The second issue is something new, and the combination of both is entirely different to anything we've seen before. But like many things in calculus, we can solve our problems by zooming in and looking at small quantities. </p>
  <p> If we zoom in on a very particular point on our path in space, we can construct an approximation for work for a very small change in distance. We take the vector which represents our force and dot it with a vector representing a small change on our curve, a straight line which gets better and better as our gaps get smaller. We add all of these up to get our total work. This is, again an integral. What's notable here, however, is that we're basically integrating a bunch of dot products along a curve. That's what a line integral over a vector field is, by the way, integrating the dot products of our vector field and our curve. As a result, our notation is going to change. It now looks like this. [insert image here]. Notice that both F (our vector field) and ds (our small change in arc length) are vectors. There's a bit of a difference now, though. If we're taking dot products, we need to have a vector-valued representation of our small change in arc length. This simplifies thing a little bit--we don't have to use the Pythagorean theorem anymore because we're just dotting components with each other. So we have a vector representing components of our arc in each direction like so [image]. Okay, but now we need a vector to represent a small change in arc length. Well, our small change in the arc length vector is going to represent a small change in time (again, this is how I imagine parametric functions. Time doesn't really have a role in determining work, though.) multiplied by the rate of change of our arc (this is just the age-old idea of total change equals time times rate, or d=rt). This rate of change, of course, is going to be the derivative of our curve. However, now that we're dealing with vectors, it's more accurate to say that we're taking the derivartive of each directional component. In other words, we have this equality [image]. Now, let's look at what our integral looks like right now.  </p>
  <p> Ok, so we have a basic idea of what we need to do, but the hard part is figuring out something to do to help compute it. The vector representing force is the easy part--we're already given a vector field. What about the vector representing a small change along our curve? By now we already know that in order to get everything into a single integral, we're going to need to parameterize our arc length. </p>
  <p> If we want everything to be with respect to one variable, then we also have to parametrically define our vector field. Our curve is already dependent on t, and the strength of our force vector is dependent on our position on the curve, so we can plug in our parametrically defined components of x, y, and z from our curve function into our vector field to create this integral [image]. </p>
  <p>
</body>
