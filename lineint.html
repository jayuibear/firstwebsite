<head>
<title> Line Integrals </title>
<link href="style.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
<style>
p {
  font-family: 'Open Sans', sans-serif;
}
h2 {
  font-family: 'Open Sans', sans-serif;
  }
 </style>
</head>
<body>
<h1> Line integrals </h1>
<h2> Introduction </h2>
<p> In calculus of a single variable, change seemed quite easy to measure. When we investigated the notion of the directional derivative, however, we realized that once you include more dimensions, the possibilities become endless. We could see how much a function would change for a small step in any direction, not just along the x or y axes. Even around one point, the behavior of a function could change significantly depending on the direction we were headed.</p>
<p> What about integrals, then? What about integrals in a certain direction? This might seem preposterous at first. After all, integrals in space occur over entire regions, so it's not like we can just pick a direction to go with. But recall one of the geometric interpretations of double integrals--the idea of cross sections being integrated across an axis. For the sake of that chapter, we looked at cross sections for traces with respect to one axis and then integrated again to form a double integral. However, we limited these cross sections to be perpendicular to the axes. Who says we can't have a cross section that follows a diagonal path underneath the curve? Remember, a cross section's area is just an integral in two dimensions, which is just a single integral. You might wonder if perhaps we can construct this sort of integral. We'd be going on some heterodox path for sure, but it's area under a curve, a concept from Calculus I.</p>
<p> So how would we go about doing this? Imagine we have some sort of surface f(x,y), and we want to find the "directional integral" going diagonally across the floor like so: [IMAGE HERE]. What I mean is, imagine findnig the area underneath the surface along that line. By restricting the surface to just that line, however, we're basically doing a very simple integration. We still need to know how we'd calculate it, though. </p>
<p> The first question we should ask to try to tackle this problem is, "With respect to what are we integrating?" It's not with respect to x or y. We might be tempted to say both, but that would create a double integral. It seems as if we're integrating with respect to the line on the floor, but how do we express that? We can't express our bounds in both x and y at the same time, then we'd have two variables! We need a way to use a single integral to repersent tiny changes in both x and y.</p>
<p> So, let's recap what we've figured out so far. We need to integrate along the line on the floor. The line has both changing x and y values. If only we had a way to make x and y both dependent on some other variable. At this point, a light bulb should go off in your head. Make x and y dependent on some other variable? Let's parametrically define our line. The line in question here is simply y=x, which we could represent as x(t) = t, and y(t) = t. We see that a change "on the line" is really the change of the hypotenuse of a right triangle formed by changes in both x and y. Before we dig deeper into this aspect, let's remind ourselves what an integral is. It's the limit of a bunch of Riemann sums, more specifically, the areas of rectangles, only this time, our rectangle width is a little bit of the length of the line. Our height, of course, is the value of the function at a point on this small bit of length. So the area of each rectangle is "value of function" times "small bit of arc length". We of course will sum these and take the limit as the width of these rectangles approaches 0.</p>
<p> We want to integrate everything with respect to one variable, t. I always imagine t as being time--imagine traveling along this curve over a period of time and gradually adding these rectangles.</p>
<p> Let's do the easy part first, which is defining our function parametrically. The example I gave is z = x^2 + y^2. Since x and y both equal t, we can say that z= 2t^2. Think about what that means. For any bit of time (let's say, I don't know, seconds?) the height of our curve is equal to twice to our amount of time in seconds squared. Now, we need to represent our small change in arc length, which we conventionally call dS. Well, we're going to say that this tiny change in arc length is equal to a tiny change in time multiplied by something. What is this something? Well, it's going to be the length of our hypotenuse. This is of course, [insert link]. We eventually end up with [insert link]. Think about it. That makes sense, right? On a straight line, for a small change in time, the change in the hypotenuse is also going to be linear, just with a different slope.</p>
<p> So, where do we end up? Now that we have everything in terms of t, let's put it together. We end up with this integral: [put image here]. So, what if we want to integrate from (0,0) to (1,1)? You might be tempted to say it's the integral from 0 to 1. Well, in this case you'd be right, but remember, we have to consider what values of t correspond to the bounds of integration. Our final definite integral is thus [insert image].</p>
<p> Wow. Think about what we did for a second. We basically found a way to evaluaet a directional integral. And for our line, it's not really too different from a directional derivative in the reverse direction. I mean, we're just integrating our original function multiplied by some constant which accounts for our Pythagorean shenanigans. There's a more formal name for this "directional integral"--a line integral. The notation looks like this: [insert image]</p>
<p> Play around with this for different functions. If you spent a long enough time doing that, a thought might cross your mind. You could connect a bunch of these lines and calculate these line integrals, each next one starting where the last one left off. You can make these really interesting lined paths for yourself. Now, ask yourself, what would happen if we took a bunch of tiny lines and connected them together? That's right. Then we'd be looking at a curve. We can make these line integrals go over curves now! </p>
<p> No, you don't have to integrate a line integral again to account for the many different tiny lines that form up a curve. That's actually already covered in our original definition of the line integral, specifically, defining the arc length parametrically. Remember, if we zoom into certain parts of our curve, our "right triangle" will look different, meaning that our derivatives will carry different values as well. These derivatives are derived from our original function which we've defined parametrically, and our derivatives are already defined parametrically inside of our arc length formula. That means that as long as we can define our little path parametrically, we can find these the areas marked by these "cross sections." Now I think that's pretty cool, don't you? These are still called line integrals, by the way, even though they're over curves. </p>
  <h2> Vector Fields and Scalar Fields </h2>
  <p> We now have this notion of being able to accumulate a function along a certain path. This is super useful, particularly in physics. For example, we've seen that we can calculate the work done along a straight path by a force using dot products, but with a line integral, you can find the work done on a curvy path. So many things involve going from Point A to Point B, but few of them are just purely straight lines. So, let's say we want to find the work done by gravity in space onto a planet traveling on a certain path (a very useful application in astronomy). Okay, let's look at our function that we're integrating! [Insert picture of a vector field] Hmm, this is interesting. I mean, it makes sense, right? We represent force through vectors, so we're basically taking our line integral through all of these force vectors though. There's a bit of a problem, though. This collection of vectors isn't exactly like a function that we're used to, right? Normally, we'd say that when we input some values, we get another piece of our coordinate as our output. Now, though, we're inputting points and getting a vector as an output. And the important part is that we can't just represent these vectors with one number. We have to take directions into account. It's not as simple as z = f(x,y) anymore. Now, every value of x, y, and z is associated with components of vectors going in certain directions with different strengths depending on where we are in space. We're going to need a new type of function. </p>
  <p> This sort of function will require a point as an input and a vector as an output. In other words, for some point (x,y,z), our function f(x,y,z) will give us a vector. The x component of our vector will be some function of x, y, and z. Look at the diagram of the gravitational field, particularly the x components of these vectors. Notice that their relative directions and strengths depnd on where they are in space. When the actual value of x is positive, the x component of our vector is negative because it's pointing towards the origin (where our celestial body is). When x is negative, the component is positive. Notice that the x component depends on our values of y and z as well. We can apply this same logic to the y and z components. The point is, we have functions that describe the behavior of these vectors at each and every point. Again, it makes sense conceptually from the picture. </p>
  <p> As much sense as this makes, there was something that always threw me off. In our gravity diagram, we see that the x-component of each vector depends on our value of x. It's easy to get yourself confused and say, "What? x depends on x? That doesn't make any sense? How can a variable depend on itself?" But really these are two different things that have to do with the notion of x. One is our input, the value of x in space. The other is our output, the srtength of our vector in the direction parallel to the x-axis.</p>
  <p> So what on earth do we call this kind of function, and how do we notate it? Well,we call this collection of vectors a vector field. "Regular" functions are called scalar fields because sets of input values are associated with numbers. Normally, we don't call numbers "scalars," but we have to make the distniction now. Scalars are purely numbers--magnitudes. Vectors have direction, which we have to accoutn for now. </p>
  <p> Well, vector fields are new now, right? No, actually, can you think of something we've done in the past that inputs points and outputs numbers? Well, there's the gradient! The gradient is a type of vector field, is it not? We input some point, and we get a vector whose components are dependent on that point. Until now, though, we've associated gradient vector fields with some other parent function (technically called a potential function). This is actually a special susbet of vector fields caleld cosnervative vector fields, which are gradients of some scalar field. There are, however, vector fields that are not gradients of some other field. This also came as a surprise to me at first. In single-variable calculus, we learned that every functino has an antiderivative, even if it cannot be expressed with elementary mathematical functions. We can sort of think of gradients as "vector derivatives," so it can be surprising to know that some of these fields don't have a parent function. This disparity arises from the fact that there is some relationship between the different components of a vector field. For example, imagine if the x component of our vector field was x^2 + y^2, and that our y component was e^x *sin(y)*ln(z). It's impossible to think of a function whose partial derivatives with respect to x and y respectively match up with that. We'll talk more about special properties of conservative vector fields later </p>
  <p> So, going back to the idea of calculating a line intergral across this vector field, what would we even do? Well, we know that on a straight line, work is simply force dot distance [image]. Now, though, we have two issues. We have paths that aren't straight, and we have forces that aren't constant. The first issue should be more familiar by now since we've already done line integrals over scalar fields. The second issue is something new, and the combination of both is entirely different to anything we've seen before. But like many things in calculus, we can solve our problems by zooming in and looking at small quantities. </p>
  <p> If we zoom in on a very particular point on our path in space, we can construct an approximation for work for a very small change in distance. We take the vector which represents our force and dot it with a vector representing a small change on our curve, a straight line which gets better and better as our gaps get smaller. We add all of these up to get our total work. This is, again an integral. What's notable here, however, is that we're basically integrating a bunch of dot products along a curve. That's what a line integral over a vector field is, by the way, integrating the dot products of our vector field and our curve. As a result, our notation is going to change. It now looks like this. [insert image here]. Notice that both F (our vector field) and ds (our small change in arc length) are vectors. There's a bit of a difference now, though. If we're taking dot products, we need to have a vector-valued representation of our small change in arc length. This simplifies thing a little bit--we don't have to use the Pythagorean theorem anymore because we're just dotting components with each other. So we have a vector representing components of our arc in each direction like so [image]. Okay, but now we need a vector to represent a small change in arc length. Well, our small change in the arc length vector is going to represent a small change in time (again, this is how I imagine parametric functions. Time doesn't really have a role in determining work, though.) multiplied by the rate of change of our arc (this is just the age-old idea of total change equals time times rate, or d=rt). This rate of change, of course, is going to be the derivative of our curve. However, now that we're dealing with vectors, it's more accurate to say that we're taking the derivartive of each directional component. In other words, we have this equality [image]. Now, let's look at what our integral looks like right now.  </p>
  <p> Ok, so we have a basic idea of what we need to do, but the hard part is figuring out something to do to help compute it. The vector representing force is the easy part--we're already given a vector field. What about the vector representing a small change along our curve? By now we already know that in order to get everything into a single integral, we're going to need to parameterize our arc length. </p>
  <p> If we want everything to be with respect to one variable, then we also have to parametrically define our vector field. Our curve is already dependent on t, and the strength of our force vector is dependent on our position on the curve, so we can plug in our parametrically defined components of x, y, and z from our curve function into our vector field to create this integral [image]. </p>
  <h2>The Fundamental Theorem for Line Integrals</h2>
  <p>So, we've been using this idea of integrating force to find work across a curve. Keep that in mind, but let's shift to a somewhat different idea also involving force and work. Let's look at another physics concept: velocity. We know that velocity accumulated over time is displacement. Let's pretend we have a person being pushed around by some water currents, and we have a vector field that represents the velocity of the water. I'm not going to draw the field, but imagine that the person travels in a path like this. [image] There's two ways we can calculate the distance traveled. The first thing we could do is integrate velocity alnog this curve. Alternatively, we can just calculate the distance between the two points, which is what we do normally. Okay, now, what if our little swimmer here was somehow able to fight against the currents and travel in this path? [image] Well, even if our swimmer is somehow going against the current, the idea of dot products as giving magnitudes of components helps out. We can still take the line integral along this path to find the total displacement. But wait, hold on, this displacement is going to end up being the same. In fact, we could take any path between these two points, and displacement would be the same. All we need to know is our starting point and end point, and we can plug it into a formula for displacement. </p>
  <p> When I first learned this, I was comletely blown away. Line integrals with this quality are known as path-independent. Other path-indepndent functions include, for example, scaling a mountain. It doesn't matter how you scale the mountain, if you accumulate all of the "steepness", you'll ascend the same altitude if you start and end at the same place. Okay, so the question is, what kind of vector field is path-indepndent? Well, let's think about both of those scenarioes. What is velocity? Velocity is just the derivative of position, is it not? So a velocity vector would just give you the derivative of position in each direction. What about the idea of saclinga  mountain? You'd be given vectors that represent steepness in every direction. Steepness is just the derivative of altitude--how much you're going up for a small change in position. </p>
  <p> So in both of these cases, it seems that we're just integrating a derivative. Hey, by the way, you know what they call the steepness of something? It's called a gradient, and a gradient is exactly what we're dealing with here--a line integral of a vector field that represents the partial derivatives of some other function. This is an extremely powerful tool. It literally does not matter what path you take. The only information you need to know is the potential function and the starting and end point. As mind-blowingly amazing as that sounds, we're very familiar with this concept in single-variable calculus--the fundamental theorem of calculus. [insert image] We've calcualted net change before by looking at some potential function at a starting point and at an endpoint. The same exact concept appears here, except the fact that we can do this over a three dimensional region is amazing, but hopefully it makes sense. It's just hard to wrap your head around at first.</p>
  <p> The most general way to state this idea is that line integrals of conservative vector fields are path-independent. How do we know if a vector field is conservative? Well, if it's the gradient of a potential function. Ok, stupid, how do we know if it's a gradient? Well, there's a nice fact about partial derivatives that we can use for two-dimensional vector fields (there's another system for three dimensional ones). It's symmetry of mixed partials, also known as Clairaut's Theorem. How are we going to use that here? Well, if a vector field is a gradient, that means that each component is already a partial derivative with respect to z [image]. Okay, now what if we took the partial derivative of the x component with respect to y, and the partial derivative of the y component with respect to x? Well, we'd have this. [image] These partials must be equal to each other because of Clairaut's Theorem. As long as these two are equal, we know that our vector field is conservative in R2. This idea is a good way to remember the formula for Green's Theorem down the road, which we'll get to. </p>
  <p> This also brings to light the fact that the line integral of a conservative vector field over a closed path is 0. Why? Because you're starting and ending in the same place! If our swimmer starts and ends in the same place, displacement is zero. If our mountain climber starts and ends up on the same spot, there's no net change in altitude. </p>
  <p> So we've determined whether or not a vector field is conservative. This fact makes it a lot easier to evaluate line integrals over paths that are different to parameterize or evaluate parametrically. How do we work backwards, then? How are we going to find our potential function from a conservative field? I'll give the 2-d version for now since we haven't looked at 3-d conservative fields yet. Anyway, let's think about a simpler case first. How do we find the potential function for a simple one variable function that's known to be a derivative? Simple, all we have to do is find the indefinite integral of our function. Now, when I first learned about the higher dimentional equivalent for this, I became a bit uneasy. We hadn't done any indefinite integrals in three dimensions. What are we supposed to do? I mean, here's an example. Suppose our partial with respect to x is 1. Okay, so we know that our function contains the term x. The problem, though, is that our potential function could be x + e^y, x+sin(y), or x+ e^yln(y)/sqrt(sec(y)). All functions strictly in terms of y get compeltely eliminated when the partial derivative operator is used with respect to x. </p>
  <p> The key, here, is to compare. We actually have all the information we need--partial derivatives with respect to both x and y. We can find "traces" (not in the mathematical sense, I mean like when you track something) of the x and y terms in the partials. Any functions of y that get eliminated by partials with respect to x survive in the partials with respect to y. Let's work through an example. </p>
  <p> Perhaps we're given the following information: [partial with respect to x is xy, partial with respect to y is (1/2)x^2+4] We're going to integrate the partial with respect to x, first. What's the integral of xy with respect to x? Well, it's x^2*y/2 + f(y). Think about why this makes sense. When we did indefinite integrals with single variable calculus we added a constant of integration. Now, however, we add an entire function in terms of y. So what do we do now? Well, we're going to work our way down to the partial with respect to y to see if we have any discrepancies. Okay. let's take the partial with respect to y of x^2y/2 + f(y). We get (1/2)x^2 + f'(y). Let's compare this to our given partial with respect to y. Hmm. We were given (1/2)x^2 + 4. Therefore, f'(y) = 4, amd so f(y) = 4y + c. Our potential function ensd up being (1/2)x^2+4y+C </p>
  
